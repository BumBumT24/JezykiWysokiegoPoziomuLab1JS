{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GD92d3O0Ez29"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "npz = np.load('Audiobooks_data_train.npz')\n",
        "\n",
        "train_inputs = npz['inputs'].astype(np.float32)\n",
        "train_targets = npz['targets'].astype(np.int32)\n",
        "\n",
        "npz = np.load('Audiobooks_data_validation.npz')\n",
        "validation_inputs, validation_targets = npz['inputs'].astype(np.float32),npz['targets'].astype(np.int32)\n",
        "\n",
        "npz = np.load('Audiobooks_data_test.npz')\n",
        "test_inputs, test_targets = npz['inputs'].astype(np.float32),npz['targets'].astype(np.int32)"
      ],
      "metadata": {
        "id": "_h8Sbh9sFPhU"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "train_inputs = scaler.fit_transform(train_inputs)\n",
        "validation_inputs = scaler.transform(validation_inputs)\n",
        "test_inputs = scaler.transform(test_inputs)\n",
        "\n",
        "# Define model with Functional API\n",
        "inputs_size = train_inputs.shape[1]  # Dynamically get input size\n",
        "inputs = tf.keras.Input(shape=(inputs_size,))\n",
        "x = tf.keras.layers.Dense(256, activation='relu')(inputs)\n",
        "x = tf.keras.layers.BatchNormalization()(x)\n",
        "x = tf.keras.layers.Dropout(0.3)(x)\n",
        "\n",
        "# Residual block\n",
        "residual = x\n",
        "x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
        "x = tf.keras.layers.BatchNormalization()(x)\n",
        "x = tf.keras.layers.Dropout(0.3)(x)\n",
        "x = tf.keras.layers.add([x, residual])  # Skip connection\n",
        "\n",
        "outputs = tf.keras.layers.Dense(2, activation='softmax')(x)\n",
        "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "optimizer = tf.keras.optimizers.AdamW(learning_rate=0.001, weight_decay=1e-4)\n",
        "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "wv6TXRagGKWV"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "\n",
        "max_epochs = 100\n",
        "\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_accuracy', patience=5, restore_best_weights=True\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    train_inputs, train_targets,\n",
        "    batch_size=64,\n",
        "    epochs=200,\n",
        "    validation_data=(validation_inputs, validation_targets),\n",
        "    callbacks=[early_stopping],\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Z13R0CGGo3G",
        "outputId": "473068a9-cd3e-4999-ba5a-77da839b997c"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.5805 - loss: 1.0205 - val_accuracy: 0.6853 - val_loss: 0.6248\n",
            "Epoch 2/200\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6697 - loss: 0.7284 - val_accuracy: 0.6384 - val_loss: 0.6449\n",
            "Epoch 3/200\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6577 - loss: 0.7009 - val_accuracy: 0.6696 - val_loss: 0.6047\n",
            "Epoch 4/200\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6739 - loss: 0.6589 - val_accuracy: 0.6674 - val_loss: 0.6037\n",
            "Epoch 5/200\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6624 - loss: 0.6554 - val_accuracy: 0.6920 - val_loss: 0.5885\n",
            "Epoch 6/200\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6777 - loss: 0.6178 - val_accuracy: 0.7188 - val_loss: 0.5632\n",
            "Epoch 7/200\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6783 - loss: 0.6080 - val_accuracy: 0.7009 - val_loss: 0.5780\n",
            "Epoch 8/200\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6850 - loss: 0.5963 - val_accuracy: 0.7254 - val_loss: 0.5479\n",
            "Epoch 9/200\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7119 - loss: 0.5681 - val_accuracy: 0.7076 - val_loss: 0.5531\n",
            "Epoch 10/200\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6980 - loss: 0.5851 - val_accuracy: 0.7210 - val_loss: 0.5543\n",
            "Epoch 11/200\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6833 - loss: 0.5836 - val_accuracy: 0.7232 - val_loss: 0.5432\n",
            "Epoch 12/200\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6952 - loss: 0.5665 - val_accuracy: 0.7277 - val_loss: 0.5561\n",
            "Epoch 13/200\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6997 - loss: 0.5661 - val_accuracy: 0.7254 - val_loss: 0.5382\n",
            "Epoch 14/200\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6967 - loss: 0.5628 - val_accuracy: 0.7232 - val_loss: 0.5530\n",
            "Epoch 15/200\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7102 - loss: 0.5440 - val_accuracy: 0.7210 - val_loss: 0.5512\n",
            "Epoch 16/200\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6915 - loss: 0.5666 - val_accuracy: 0.7321 - val_loss: 0.5445\n",
            "Epoch 17/200\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6818 - loss: 0.5805 - val_accuracy: 0.7321 - val_loss: 0.5366\n",
            "Epoch 18/200\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7030 - loss: 0.5647 - val_accuracy: 0.7143 - val_loss: 0.5513\n",
            "Epoch 19/200\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7085 - loss: 0.5578 - val_accuracy: 0.7299 - val_loss: 0.5382\n",
            "Epoch 20/200\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7082 - loss: 0.5404 - val_accuracy: 0.7121 - val_loss: 0.5552\n",
            "Epoch 21/200\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7117 - loss: 0.5547 - val_accuracy: 0.7121 - val_loss: 0.5598\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_inputs, test_targets)\n",
        "print('\\nTest loss: {0:.2f}. Test accuracy: {1:.2f}%'.format(test_loss, test_accuracy*100.))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGDCdVy9G6Zt",
        "outputId": "94f4d034-c166-48e6-bdf6-4e82b5b2db6a"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7236 - loss: 0.5461  \n",
            "\n",
            "Test loss: 0.54. Test accuracy: 73.21%\n"
          ]
        }
      ]
    }
  ]
}